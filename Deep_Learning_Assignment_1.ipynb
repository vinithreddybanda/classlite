{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **CIFAR-100**"
      ],
      "metadata": {
        "id": "0DYIPtD55m7y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "do_rsUcb5lA5"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Load CIFAR-100 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Split into train and validation\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=42)\n",
        "\n",
        "# Build model function\n",
        "def build_model(input_shape, num_hidden_layers=3, neurons_per_layer=128, activation='relu', optimizer='adam', dropout_rate=0.0):\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=input_shape))\n",
        "\n",
        "    for _ in range(num_hidden_layers):\n",
        "        model.add(Dense(neurons_per_layer, activation=activation))\n",
        "        if dropout_rate > 0:\n",
        "            model.add(Dropout(dropout_rate))\n",
        "\n",
        "    model.add(Dense(100, activation='softmax'))\n",
        "\n",
        "    if optimizer == 'sgd':\n",
        "        opt = SGD()\n",
        "    elif optimizer == 'adam':\n",
        "        opt = Adam()\n",
        "    elif optimizer == 'rmsprop':\n",
        "        opt = RMSprop()\n",
        "\n",
        "    model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Train model function\n",
        "def train_model(model, x_train, y_train, x_val, y_val, batch_size=32, epochs=10):\n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=3)\n",
        "    history = model.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size=batch_size, epochs=epochs, callbacks=[early_stop])\n",
        "    return history\n",
        "\n",
        "# Train and evaluate model\n",
        "model_cifar100 = build_model(input_shape=(32, 32, 3), num_hidden_layers=3, neurons_per_layer=128, optimizer='adam', activation='relu')\n",
        "history_cifar100 = train_model(model_cifar100, x_train, y_train, x_val, y_val, batch_size=32, epochs=10)\n",
        "\n",
        "test_loss_100, test_acc_100 = model_cifar100.evaluate(x_test, y_test, verbose=2)\n",
        "print(f\"CIFAR-100 Test accuracy: {test_acc_100}\")\n",
        "\n",
        "# Confusion Matrix\n",
        "y_pred_100 = np.argmax(model_cifar100.predict(x_test), axis=1)\n",
        "cm_100 = confusion_matrix(y_test, y_pred_100)\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(cm_100, annot=False, cmap='Blues', xticklabels=range(100), yticklabels=range(100))\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('CIFAR-100 Confusion"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CIFAR-10**"
      ],
      "metadata": {
        "id": "Guy3rgUE5zK7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Split into train and validation\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=42)\n",
        "\n",
        "# Build model function\n",
        "def build_model(input_shape, num_hidden_layers=3, neurons_per_layer=64, activation='relu', optimizer='adam', dropout_rate=0.0):\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=input_shape))\n",
        "\n",
        "    for _ in range(num_hidden_layers):\n",
        "        model.add(Dense(neurons_per_layer, activation=activation))\n",
        "        if dropout_rate > 0:\n",
        "            model.add(Dropout(dropout_rate))\n",
        "\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    if optimizer == 'sgd':\n",
        "        opt = SGD()\n",
        "    elif optimizer == 'adam':\n",
        "        opt = Adam()\n",
        "    elif optimizer == 'rmsprop':\n",
        "        opt = RMSprop()\n",
        "\n",
        "    model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Train model function\n",
        "def train_model(model, x_train, y_train, x_val, y_val, batch_size=32, epochs=5):\n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=3)\n",
        "    history = model.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size=batch_size, epochs=epochs, callbacks=[early_stop])\n",
        "    return history\n",
        "\n",
        "# Hyperparameter tuning\n",
        "hyperparameters = {\n",
        "    \"epochs_list\": [5, 10],\n",
        "    \"hidden_layers_list\": [2, 4],\n",
        "    \"neurons_list\": [128, 256],\n",
        "    \"batch_size_list\": [32, 64],\n",
        "    \"optimizers\": ['adam', 'rmsprop'],\n",
        "    \"activation_functions\": ['relu', 'sigmoid']\n",
        "}\n",
        "\n",
        "best_accuracy = 0\n",
        "best_model = None\n",
        "best_config = {}\n",
        "\n",
        "for epochs in hyperparameters[\"epochs_list\"]:\n",
        "    for num_layers in hyperparameters[\"hidden_layers_list\"]:\n",
        "        for neurons in hyperparameters[\"neurons_list\"]:\n",
        "            for batch_size in hyperparameters[\"batch_size_list\"]:\n",
        "                for optimizer in hyperparameters[\"optimizers\"]:\n",
        "                    for activation in hyperparameters[\"activation_functions\"]:\n",
        "                        print(f\"Training with: {epochs} epochs, {num_layers} layers, {neurons} neurons, {batch_size} batch size, {optimizer} optimizer, {activation} activation\")\n",
        "                        model = build_model(input_shape=(32, 32, 3), num_hidden_layers=num_layers, neurons_per_layer=neurons, optimizer=optimizer, activation=activation)\n",
        "                        history = train_model(model, x_train, y_train, x_val, y_val, batch_size=batch_size, epochs=epochs)\n",
        "\n",
        "                        val_acc = max(history.history['val_accuracy'])\n",
        "                        if val_acc > best_accuracy:\n",
        "                            best_accuracy = val_acc\n",
        "                            best_model = model\n",
        "                            best_config = {'epochs': epochs, 'num_layers': num_layers, 'neurons': neurons, 'batch_size': batch_size, 'optimizer': optimizer, 'activation': activation}\n",
        "\n",
        "print(f\"Best model config: {best_config} with validation accuracy: {best_accuracy}\")\n",
        "\n",
        "# Evaluate best model on test set\n",
        "test_loss, test_acc = best_model.evaluate(x_test, y_test, verbose=2)\n",
        "print(f\"Test accuracy: {test_acc}\")\n",
        "\n",
        "# Confusion Matrix\n",
        "y_pred = np.argmax(best_model.predict(x_test), axis=1)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Reds', xticklabels=range(10), yticklabels=range(10))\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "skAJhqXQ5yHg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}